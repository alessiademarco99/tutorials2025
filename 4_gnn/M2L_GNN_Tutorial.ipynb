{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üåé Overview\n",
        "\n",
        "Welcome to the Graph Neural Network tutorial! In this notebook, you will learn how to implement different types of GNN models across an array of different tasks and datasets. Graphs and message passing neural networks lay at the heart of many popular models used today, so we encourage you to read through all of the content carefully. If you have any questions or concerns, please do not hesitante to ask one of the demonstrators. And with that, let's begin! üèÅ\n",
        "\n",
        "**Objectives:**\n",
        "\n",
        "1.  Understand the basics of GNNs\n",
        "2.  Implement simple GNN and MLP models using PyTorch and PyTorch Geometric\n",
        "3.  Train and evaluate your models on node classification and graph regression tasks\n",
        "4.  Learn about graph visualization, mini-batching, and over-smoothing\n",
        "\n",
        "Authors: Emily Jin (emily.jin@m2lschool.org) and Mikhail Galkin (mikhail.galkin@m2lschool.org)\n",
        "\n",
        "Memes created by: Emily Jin\n",
        "\n",
        "*Based off of a collection of notebooks by √Ålvaro Arroyo, Federico Barbero, Cristian Bodnar, Iulia Duta, Ben Finkelshtein, Charlie Harris, Emily Jin, Chaitanya K. Joshi, Haitz S√°ez de Ocariz Borde, Paul Scherer, and Ramon Vi√±as Torn√©.*\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1S497o4HDVZF303ZJF10zzngW1bGIHMWr\" width=\"500\">\n",
        "</center>"
      ],
      "metadata": {
        "id": "_Mlbf6IXZjjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üõ†Ô∏è Section 0: Notebook setup\n",
        "\n",
        "First, we need to configure this notebook with the correct dependencies. In order to enable GPU acceleration for your notebook, navigate to be done by navigating to `Runtime > Change runtime type > Hardware accelerator > T4 GPU > Save`. If you are unable to get a GPU, this notebook will still work with a CPU, but model training may take longer.\n",
        "\n",
        "Some other tips & tricks:\n",
        "- Press `Shift + Enter` to run a cell and move to the next one (`Ctrl + Enter` to only run it)\n",
        "- When you execute a cell, the variables you create are saved into a global namespace. As a consequence, changes in the code will not take effect until you re-run that specific cell.\n",
        "- Remember to save your notebook every once in a while!\n",
        "\n",
        "This notebook relies on the use of PyTorch. Pleases follow the instructions below to ensure the correct version is installed."
      ],
      "metadata": {
        "id": "fq9mhJ5lo7Gi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check PyTorch version installed on this system\n",
        "!python -c \"import torch; print(torch.__version__)\""
      ],
      "metadata": {
        "id": "wOS8byWno6Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Download the corresponding PyTorch Geometric module\n",
        "\"\"\"\n",
        "Assign TORCH variable to the value you get from the cell above. E.g., export TORCH=1.12.1+cu113\n",
        "\"\"\"\n",
        "%env TORCH=2.6.0+cu124 # Update this to match the value from the cell above\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-geometric networkx matplotlib"
      ],
      "metadata": {
        "id": "uvLG28XMUSCF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [Run me] Import python modules\n",
        "\n",
        "# Let's first import all the things we will need for the first part of this tutorial\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "# from torch_scatter import scatter\n",
        "from torch_geometric.utils import scatter\n",
        "\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.loader import DataLoader\n",
        "import torch_geometric.utils as U\n",
        "from torch_geometric.datasets import KarateClub\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "from IPython.display import HTML, display, Javascript\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set your device to GPU on the backend\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "_r22OObnhMxN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üì© Section 1: Message passing\n",
        "\n",
        "Before you begin implementing your own GNN, we will first visualize a simple message passing implementation on the Karate Club dataset. In this toy example, each node feature initially contains a feature value of 1.00, and at each subsequent \"layer\" or iteration, the node features are updated with the sum of the features of all it's neighbors. This mimics the message-passing paradign that most popular GNN models are based on.\n",
        "\n",
        "Use the slider to see how node colorings (i.e. features) evolve from layer to layer, and hover over a nodes to its exact feature value.\n",
        "- How does node degree affect the resulting feature values?\n",
        "- What do you notice about nodes that have similar connectivity?"
      ],
      "metadata": {
        "id": "yp5jqbPCvh1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [Run me] Interactive visualization\n",
        "\n",
        "# Load a small graph (Karate Club for simplicity and clarity)\n",
        "dataset = KarateClub()\n",
        "data = dataset[0]\n",
        "\n",
        "# Convert to NetworkX for visualization\n",
        "G = to_networkx(data, to_undirected=True)\n",
        "\n",
        "# Simulate node features (e.g., 1D feature per node)\n",
        "num_nodes = data.num_nodes\n",
        "features = torch.ones(num_nodes, 1)  # Initial features\n",
        "history = [features.clone()]  # Store feature history at each hop\n",
        "\n",
        "# Define a simple message passing: mean of neighbors\n",
        "edge_index = data.edge_index\n",
        "\n",
        "def message_passing(x, edge_index):\n",
        "    out = torch.zeros_like(x)\n",
        "    # Using scatter_add for efficient message passing\n",
        "    out = scatter(x[edge_index[0]], edge_index[1], dim=0, dim_size=x.size(0), reduce='sum')\n",
        "    deg = scatter(torch.ones_like(x[edge_index[0]]), edge_index[1], dim=0, dim_size=x.size(0), reduce='sum')\n",
        "\n",
        "    deg[deg == 0] = 1  # Avoid division by zero\n",
        "    return out\n",
        "\n",
        "# Perform message passing for up to 5 hops\n",
        "for i in range(5):\n",
        "    features = message_passing(features, edge_index)\n",
        "    history.append(features.clone())\n",
        "\n",
        "# Normalization is removed as per user request, but keeping the function structure\n",
        "def get_features(x):\n",
        "    return x\n",
        "\n",
        "raw_history = [get_features(h).squeeze().tolist() for h in history]\n",
        "\n",
        "\n",
        "# Build node and edge data for D3.js\n",
        "nodes = [{'id': i, 'feature': raw_history[0][i]} for i in range(num_nodes)]\n",
        "edges = [{'source': int(s), 'target': int(t)} for s, t in edge_index.t().tolist()]\n",
        "\n",
        "# Convert to JSON\n",
        "graph_json = {\n",
        "    'nodes': nodes,\n",
        "    'links': edges,\n",
        "    'raw_features': raw_history # Raw features for tooltip and coloring\n",
        "}\n",
        "\n",
        "# Pass data to JavaScript for rendering\n",
        "# Correcting the HTML string formatting by using f-string and escaping curly braces\n",
        "display(HTML(f\"\"\"\n",
        "<style>\n",
        ".tooltip {{\n",
        "    position: absolute;\n",
        "    text-align: center;\n",
        "    padding: 8px;\n",
        "    font: 12px sans-serif;\n",
        "    background: lightsteelblue;\n",
        "    border: 0px;\n",
        "    border-radius: 8px;\n",
        "    pointer-events: none;\n",
        "    opacity: 0;\n",
        "    color: black;\n",
        "}}\n",
        "</style>\n",
        "<div id=\"graph\" style=\"width: 100%; height: 700px;\"></div>\n",
        "<input type=\"range\" min=\"0\" max=\"5\" value=\"0\" id=\"hopSlider\" />\n",
        "<span id=\"hopLabel\">Layer: 0</span>\n",
        "<div id=\"colorbar\" style=\"width: 300px; height: 20px; margin-top: 20px;\"></div>\n",
        "<div class=\"tooltip\"></div>\n",
        "\n",
        "<script src=\"https://d3js.org/d3.v7.min.js\"></script>\n",
        "<script>\n",
        "const graph = {json.dumps(graph_json)};\n",
        "\n",
        "const width = document.getElementById('graph').clientWidth;\n",
        "const height = document.getElementById('graph').clientHeight;\n",
        "\n",
        "const svg = d3.select(\"#graph\")\n",
        "    .append(\"svg\")\n",
        "    .attr(\"width\", width)\n",
        "    .attr(\"height\", height);\n",
        "\n",
        "// Determine the domain based on raw feature values\n",
        "let minFeature = d3.min(graph.raw_features.flat());\n",
        "let maxFeature = d3.max(graph.raw_features.flat());\n",
        "\n",
        "// interpolateViridis\n",
        "// interpolateYlGnBu\n",
        "const colorScale = d3.scaleSequential(d3.interpolateTurbo)\n",
        "    .domain([minFeature, maxFeature]);\n",
        "\n",
        "\n",
        "// Define the drag behavior\n",
        "function drag(simulation) {{\n",
        "    function dragstarted(event, d) {{\n",
        "        if (!event.active) simulation.alphaTarget(0.3).restart();\n",
        "        d.fx = d.x;\n",
        "        d.fy = d.y;\n",
        "    }}\n",
        "\n",
        "    function dragged(event, d) {{\n",
        "        d.fx = event.x;\n",
        "        d.fy = event.y;\n",
        "    }}\n",
        "\n",
        "    function dragended(event, d) {{\n",
        "        if (!event.active) simulation.alphaTarget(0);\n",
        "        d.fx = null;\n",
        "        d.fy = null;\n",
        "    }}\n",
        "\n",
        "    return d3.drag()\n",
        "        .on(\"start\", dragstarted)\n",
        "        .on(\"drag\", dragged)\n",
        "        .on(\"end\", dragended);\n",
        "}}\n",
        "\n",
        "// Add Tooltip\n",
        "const tooltip = d3.select(\".tooltip\")\n",
        "    .style(\"position\", \"absolute\")\n",
        "    .style(\"visibility\", \"hidden\");\n",
        "\n",
        "let simulation = d3.forceSimulation(graph.nodes)\n",
        "    .force(\"link\", d3.forceLink(graph.links).id(d => d.id).distance(100))\n",
        "    .force(\"charge\", d3.forceManyBody().strength(-300))\n",
        "    .force(\"center\", d3.forceCenter(width / 2, height / 2));\n",
        "\n",
        "let link = svg.append(\"g\")\n",
        "    .attr(\"stroke\", \"#aaa\")\n",
        "    .selectAll(\"line\")\n",
        "    .data(graph.links)\n",
        "    .enter().append(\"line\");\n",
        "\n",
        "let node = svg.append(\"g\")\n",
        "    .selectAll(\"circle\")\n",
        "    .data(graph.nodes)\n",
        "    .enter().append(\"circle\")\n",
        "    .attr(\"r\", 10)\n",
        "    .attr(\"fill\", d => colorScale(graph.raw_features[0][d.id])) // Use raw features for initial color\n",
        "    .call(drag(simulation));\n",
        "\n",
        "node.append(\"title\")\n",
        "    .text(d => \"Node \" + d.id);\n",
        "\n",
        "// Add hover functionality\n",
        "node.on(\"mouseover\", function(event, d) {{\n",
        "    const currentHop = +document.getElementById(\"hopSlider\").value;\n",
        "    tooltip.style(\"visibility\", \"visible\")\n",
        "           .text(\"Feature value: \" + graph.raw_features[currentHop][d.id].toFixed(2)) // Use raw features for tooltip\n",
        "           .style(\"top\", (event.pageY - 10) + \"px\")\n",
        "           .style(\"left\", (event.pageX + 10) + \"px\")\n",
        "           .style(\"opacity\", 1);\n",
        "}})\n",
        ".on(\"mousemove\", function(event){{\n",
        "    tooltip.style(\"top\", (event.pageY - 10) + \"px\").style(\"left\",(event.pageX + 10) + \"px\");\n",
        "}})\n",
        ".on(\"mouseout\", function(){{\n",
        "    tooltip.style(\"visibility\", \"hidden\").style(\"opacity\", 0);\n",
        "}});\n",
        "\n",
        "\n",
        "simulation.on(\"tick\", () => {{\n",
        "    link\n",
        "        .attr(\"x1\", d => d.source.x)\n",
        "        .attr(\"y1\", d => d.source.y)\n",
        "        .attr(\"x2\", d => d.target.x)\n",
        "        .attr(\"y2\", d => d.target.y);\n",
        "\n",
        "    node\n",
        "        .attr(\"cx\", d => d.x)\n",
        "        .attr(\"cy\", d => d.y);\n",
        "}});\n",
        "\n",
        "document.getElementById(\"hopSlider\").addEventListener(\"input\", function () {{\n",
        "    const hop = +this.value;\n",
        "    document.getElementById(\"hopLabel\").innerText = \"Layer: \" + hop;\n",
        "    node.attr(\"fill\", d => colorScale(graph.raw_features[hop][d.id])); // Use raw features for coloring\n",
        "}});\n",
        "\n",
        "// Add Color Bar\n",
        "const colorBarSvg = d3.select(\"#colorbar\")\n",
        "    .append(\"svg\")\n",
        "    .attr(\"width\", 300)\n",
        "    .attr(\"height\", 20);\n",
        "\n",
        "// Update legend scale based on raw feature domain\n",
        "const legendScale = d3.scaleLinear()\n",
        "    .domain([minFeature, maxFeature])\n",
        "    .range([0, 300]);\n",
        "\n",
        "colorBarSvg.append(\"g\")\n",
        "  .selectAll(\"rect\")\n",
        "  .data(d3.range(minFeature, maxFeature, (maxFeature - minFeature) / 100))\n",
        "  .enter().append(\"rect\")\n",
        "    .attr(\"x\", (d) => legendScale(d))\n",
        "    .attr(\"y\", 0)\n",
        "    .attr(\"width\", 300 / 100)\n",
        "    .attr(\"height\", 20)\n",
        "    .attr(\"fill\", d => colorScale(d));\n",
        "\n",
        "// Update color bar labels\n",
        "colorBarSvg.append(\"text\")\n",
        "    .attr(\"x\", 0)\n",
        "    .attr(\"y\", 15)\n",
        "    .text(minFeature.toFixed(2))\n",
        "    .style(\"fill\", \"black\");\n",
        "\n",
        "colorBarSvg.append(\"text\")\n",
        "    .attr(\"x\", 300)\n",
        "    .attr(\"y\", 15)\n",
        "    .text(maxFeature.toFixed(2))\n",
        "    .style(\"fill\", \"black\")\n",
        "    .style(\"text-anchor\", \"end\");\n",
        "\n",
        "\n",
        "</script>\n",
        "\"\"\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0EhxQRqOyoHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üìö Section 2: A GNN for Node Classification\n",
        "\n",
        "Now, you will implement a basic graph neural network model from scratch **without using PyTorch Geometric**, and prepare it for node classification. You will train your model for node classification on the Cora dataset, which is an academic citation network. The task is to predict the category of each paper, which corresponds to a node in the citation network, among the seven available.\n",
        "\n",
        "Run the code below to download and visualize the dataset. Note that the different node colorings correspond to the different node classes that your GNN model will try to predict."
      ],
      "metadata": {
        "id": "hwLX9xkQgWo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we will download the Cora dataset\n",
        "dataset = Planetoid(\"/tmp/Cora\", name=\"Cora\")\n",
        "num_nodes = dataset.data.num_nodes\n",
        "num_edges = dataset.data.num_edges // 2\n",
        "num_features = dataset.num_node_features\n",
        "num_classes = dataset.num_classes"
      ],
      "metadata": {
        "id": "muJ-TbV6muhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [Run me] Visualize a subgraph from the Cora dataset\n",
        "\n",
        "data = dataset[0]\n",
        "\n",
        "# Convert PyG graph to NetworkX format\n",
        "G = to_networkx(data, to_undirected=True)\n",
        "\n",
        "# Sample a subgraph with k-hop neighbors of a single node\n",
        "from torch_geometric.utils import k_hop_subgraph\n",
        "\n",
        "# Select a central node (e.g., node 0)\n",
        "center_node = 0\n",
        "subset, edge_index, mapping, edge_mask = k_hop_subgraph(\n",
        "    node_idx=center_node, num_hops=3, edge_index=data.edge_index, relabel_nodes=True\n",
        ")\n",
        "\n",
        "# Convert subgraph to NetworkX\n",
        "sub_data = data.subgraph(subset)\n",
        "G_sub = to_networkx(sub_data, to_undirected=True)\n",
        "\n",
        "# Draw the subgraph\n",
        "plt.figure(figsize=(8, 6))\n",
        "nx.draw(G_sub,\n",
        "        with_labels=True,\n",
        "        node_size=300,\n",
        "        node_color=sub_data.y.tolist(),\n",
        "        cmap=plt.cm.Set3,\n",
        "        font_size=10)\n",
        "plt.title(\"3-hop Subgraph Around Node 0 (Cora)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mg9Bt64EEtU3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üíª Task 1: Building a GNN from scratch\n",
        "To understand the base structure of a PyTorch neural network model `torch.nn.Module`, you will build your GNN as a class with its own instantiation of `__init__` and `forward`. You will define GNN components within `__init__`, and construct the GNN data flow in `forward`. For this task, we will focus on building a simple Graph Convolutional Network (GCN) model.\n",
        "\n",
        "Be sure to construct your model such that the number of layers is parametrized, so you can increase or decrease the number of layers simply by changing the range of an inner loop that creates the needed layers. Also, your node classification GNN should be composed of a sequence of GCN layers followed by a Multi Layer Perceptron (MLP) head used to classify each node. Therefore, you will define a separate module for each of these components, and then aggregate them together in the final model."
      ],
      "metadata": {
        "id": "Bh2SbPurluzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall that a `GCNLayer` message passing layer computes the operations as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "h_i^{(\\ell+1)} = \\sigma(W_\\text{self} h_i^{(\\ell)} + W_\\text{neigh} \\sum_{j \\in \\text{neigh}(i)} h_j^{(\\ell)})\n",
        "\\end{equation}\n",
        "\n",
        "For the first layer $\\ell=0$, $h_i^{\\ell=0} = W_{in} \\left( h_i \\right)$, where $W_{in} \\in \\mathbb{R}^{d_n}  \\rightarrow \\mathbb{R}^{d}$ is a simple linear projection (`torch.nn.Linear`) for the initial node features to hidden dimension $d$.\n",
        "\n",
        "PyTorch is realy efficient in parallelizing computations by vectorizing them. In other words, **do not** loop over all the neighbours of each node to compute the summation in the above equation; you should use instead matrix operations instead."
      ],
      "metadata": {
        "id": "D0jVmuI-u0uF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TU3I3uOMNlIe"
      },
      "outputs": [],
      "source": [
        "class GCNLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "      super().__init__()\n",
        "      # YOUR CODE HERE\n",
        "\n",
        "    def forward(self, node_feats, adj_matrix):\n",
        "      # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `GNNModule` is a collection of `GCNLayers`. In PyTorch you can create a list of layer by using `nn.ModuleList(layer_1, layer_2, ...)` or, equivalentely `nn.ModuleList(*layer_list)`. Remember activation functions!"
      ],
      "metadata": {
        "id": "MOXzfLBRuFJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNModule(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, act_fn=nn.ReLU):\n",
        "        super().__init__()\n",
        "      # YOUR CODE HERE\n",
        "\n",
        "    def forward(self, x, adj_matrix):\n",
        "      # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "TEnA7gA9pYU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `MLPModule` is a classification head that you apply to each node in the input graph after applying the graph convolutional layers. It is a collection of `nn.Linear` layers."
      ],
      "metadata": {
        "id": "Rbm-Dwnfs8kZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPModule(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, act_fn=nn.ReLU):\n",
        "        super().__init__()\n",
        "      # YOUR CODE HERE\n",
        "\n",
        "    def forward(self, x):\n",
        "      # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "kRzeNjIWXLpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's aggregate everything in a single class! Note that the `only` parameter indicates whether or not the classifier will use only the GNNModule, only the MLPModule or both. The behavior should be as follows:\n",
        "- When `only` is False, both the GNNModule and MLPModule are used\n",
        "- When `only` is set to 'mlp', only the MLPModule is used\n",
        "- When `only` is set to 'gnn', only the GNNModule is used"
      ],
      "metadata": {
        "id": "B3sUDyK6wUMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CoraNodeClassification(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        gnn_input_dim,\n",
        "        gnn_hidden_dim,\n",
        "        gnn_output_dim,\n",
        "        mlp_hidden_dim,\n",
        "        mlp_output_dim,\n",
        "        gnn_num_layers=2,\n",
        "        mlp_num_layers=2,\n",
        "        gnn_act_fn=nn.ReLU,\n",
        "        mlp_act_fn=nn.ReLU,\n",
        "        only = False,\n",
        "    ):\n",
        "        super().__init__()\n",
        "      # YOUR CODE HERE\n",
        "\n",
        "    def forward(self, x, adj_matrix):\n",
        "      # YOUR CODE HERE\n",
        "\n",
        "    # Used to reset the weights of the network when training multiple times with\n",
        "    # different hyperparameters\n",
        "    def reset_parameters(self):\n",
        "        def _reset_module_parameters(module):\n",
        "            for layer in module.children():\n",
        "                if hasattr(layer, 'reset_parameters'):\n",
        "                    layer.reset_parameters()\n",
        "                elif hasattr(layer, 'children'):\n",
        "                    for child_layer in layer.children():\n",
        "                        _reset_module_parameters(child_layer)\n",
        "\n",
        "        _reset_module_parameters(self)"
      ],
      "metadata": {
        "id": "cNVsovJTYk7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üíª Task 2: Train your GNN on node classification\n",
        "<!-- Create dedicated functions for training and testing. For training, your functions should return a vector containing the train loss and accuracy after each epoch (since Cora contains a single graph one epoch corresponds to one training iteration). You can also print out those values while the training it's running. However, given the large number of epochs, we advise you print every 8 steps or so. Your test function should return the final accuracy on the test set. If everything works correctly you should get around ~75% accuracy. -->\n",
        "With the model complete, it's time to move on to the fun part - training! Cora uses a masking approach to divide between the train and test sets. Therefore, to compute the loss/accuracy, we mask out the part of the output based on the current settings, e.g., `loss = model.loss_fn(y[data.train_mask], data.y[data.train_mask])`."
      ],
      "metadata": {
        "id": "jfeXY4_koR86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Cora dataset contains a single graph of 2708 nodes (i.e., papers).\n",
        "# We will use some of the nodes as training set and some as test set.\n",
        "data = dataset[0].to(device)\n",
        "print(data.x.size())\n",
        "\n",
        "# According to the GNN equations, we need the adjacency matrix to compute each\n",
        "# layer convolution. The following line convert the sparse data\n",
        "# (i.e., list of edges) stored in the dataset in a single dense matrix.\n",
        "adj_matrix = U.to_dense_adj(data.edge_index).squeeze(0)\n",
        "\n",
        "# Define the hyperparameters we are gonna use:\n",
        "params = {\n",
        "    \"hidden_features\": 128,\n",
        "    \"num_gcn_layers\": 2,\n",
        "    \"num_mlp_layers\": 2,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"weight_decay\": 0,\n",
        "    \"num_epochs\": 256,\n",
        "}\n",
        "\n",
        "# Move the model to the correct device using `.to(device)`\n",
        "model = CoraNodeClassification(num_features,\n",
        "                               params[\"hidden_features\"],\n",
        "                               params[\"hidden_features\"],\n",
        "                               params[\"hidden_features\"],\n",
        "                               num_classes,\n",
        "                               gnn_act_fn=nn.ReLU,\n",
        "                               mlp_act_fn=nn.ReLU,\n",
        "                               only=False\n",
        "  ).to(device)"
      ],
      "metadata": {
        "id": "UA98VowGrOtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For ease of use, we have provided you with the test and training functions. By testing a randomly initialized module, you should get around ~15% test accuracy."
      ],
      "metadata": {
        "id": "jXylCjvmmCTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, data, adj_matrix, params):\n",
        "    model.eval()\n",
        "\n",
        "    y = model(data.x, adj_matrix)\n",
        "    correct = (y[data.test_mask].argmax(dim=1) == data.y[data.test_mask]).sum()\n",
        "    test_accuracy = int(correct) / int(data.test_mask.sum())\n",
        "\n",
        "    return test_accuracy"
      ],
      "metadata": {
        "id": "h6iMWiG92wFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate your randomly initialized model. You should get ~10-15%\n",
        "test(model, data, adj_matrix, params)"
      ],
      "metadata": {
        "id": "9TmqadEefi5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With training, you should get around ~75-77% test accuracy!\n"
      ],
      "metadata": {
        "id": "tAsgIrFambqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data, adj_matrix, params):\n",
        "    model.reset_parameters()\n",
        "    model.train()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                                lr=params[\"learning_rate\"],\n",
        "                                weight_decay=params[\"weight_decay\"])\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    for e in range(params[\"num_epochs\"] + 1):\n",
        "        optimizer.zero_grad()\n",
        "        y = model(data.x, adj_matrix)\n",
        "        loss = model.loss_fn(y[data.train_mask], data.y[data.train_mask])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        correct = (y[data.train_mask].argmax(dim=1) == data.y[data.train_mask]).sum()\n",
        "        train_accuracy = int(correct) / int(data.train_mask.sum())\n",
        "\n",
        "        losses.append(loss.item())\n",
        "        accuracies.append(train_accuracy)\n",
        "        test_accuracy = test(model, data, adj_matrix, params)\n",
        "        test_accuracies.append(test_accuracy)\n",
        "        print(f\"[Epoch {e}]: Train Accuracy: {train_accuracy} | Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "    return losses, accuracies, test_accuracies"
      ],
      "metadata": {
        "id": "ycmyiU4VYOqU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train your node classification model. You should get a final test accuracy of ~75-77%\n",
        "train_losses, train_accuracies, test_accuracies = train(model, data, adj_matrix, params)\n",
        "test_accuracy = test(model, data, adj_matrix, params)\n",
        "print(\"Final test accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "fJjNaM6d3MZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By plotting the train accuracy and test accuracy over time, what can you observe?\n"
      ],
      "metadata": {
        "id": "rf6ZviVq3CVJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot train and test accuracies with matplotlib\n",
        "plt.plot(train_accuracies)\n",
        "plt.plot(test_accuracies)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vGI6Fo7n3VBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üíª Task 3: Importance of GNN and MLP modules\n",
        "Adjust the `only` parameter in your classifierd so that you only use the GNN or only use the MLP module. What is the impact of the two modules on the final result? Play around with `hidden_features` and `num_layers` a little bit and briefly describe what you observe."
      ],
      "metadata": {
        "id": "6R9lWeiNsLpD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "mhFLlmGet7r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üíª Task 4: Importance of non-linearities\n",
        "Try replacing all your activation functions with identities (or simply remove them). Do the results change? What does this tell you about this specific problem?"
      ],
      "metadata": {
        "id": "VW-V8RYft7GC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "X4ch8LoWCkWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üíª Task 5 [optional]: Improving performance\n",
        "Try fiddling around with different parts of your model and see if you can boost model performance to above 80%! Some possible options for that would be Dropout and LayerNorm layers."
      ],
      "metadata": {
        "id": "1gQAh3wUF7sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "ebdWiqBjsiRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß¨ Section 3: Exploring molecular data\n",
        "\n",
        "In the previous section, you trained a GNN for node-level prediction. Now, let's move to a graph-level task to understand **what changes you should make in the architecture**. Here, we will use a molecular dataset, since they are popular benchmarks for graph-level tasks.\n",
        "\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1P3fZ2IIfEfrbUyuqOrflq46emeFGvu6W\" width=\"500\">\n",
        "</center>\n",
        "\n"
      ],
      "metadata": {
        "id": "Z3yqquig9WXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [Run me] Install dependencies\n",
        "!pip install -q rdkit\n",
        "!pip install -q py3Dmol"
      ],
      "metadata": {
        "id": "TMa5qyKE8xwp",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [Run me] Import python modules (Note: if you get an error, you may need to run this cell twice)\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from typing import List\n",
        "\n",
        "import scipy.linalg\n",
        "from scipy.linalg import block_diag\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, ReLU, BatchNorm1d, Module, Sequential, Embedding\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.data import Batch\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.utils import remove_self_loops, to_dense_adj, dense_to_sparse\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
        "from torch_geometric.datasets import ZINC\n",
        "\n",
        "import py3Dmol\n",
        "\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, Draw\n",
        "from rdkit import RDLogger\n",
        "from rdkit.Geometry.rdGeometry import Point3D\n",
        "from rdkit.Chem import QED, Crippen, rdMolDescriptors, rdmolops\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "\n",
        "# Disable RDKit C++ logging\n",
        "RDLogger.DisableLog('rdApp.*')"
      ],
      "metadata": {
        "id": "kiGcIQR_ydsl",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [Run me] Helper functions for plots and visualization\n",
        "\n",
        "# ZINC Node labels\n",
        "atom_labels = {\n",
        "    0: 'C',\n",
        "    1: 'O',\n",
        "    2: 'N',\n",
        "    3: 'F',\n",
        "    4: 'C H1',\n",
        "    5: 'S',\n",
        "    6: 'Cl',\n",
        "    7: 'O', #'O -',\n",
        "    8: 'N', #'N H1 +',\n",
        "    9: 'Br',\n",
        "    10: 'N H3 +',\n",
        "    11: 'N H2 +',\n",
        "    12: 'N +',\n",
        "    13: 'N -',\n",
        "    14: 'S -',\n",
        "    15: 'I',\n",
        "    16: 'P',\n",
        "    17: 'O H1 +',\n",
        "    18: 'N H1 -',\n",
        "    19: 'O +',\n",
        "    20: 'S +',\n",
        "    21: 'P H1',\n",
        "    22: 'P H2',\n",
        "    23: 'C H2 -',\n",
        "    24: 'P +',\n",
        "    25: 'S H1 +',\n",
        "    26: 'C H1 -',\n",
        "    27: 'P H1 +'\n",
        "}\n",
        "\n",
        "# ZINC Edge labels\n",
        "bond_labels = {\n",
        "    1: 'SINGLE',\n",
        "    2: 'DOUBLE',\n",
        "    3: 'TRIPLE'\n",
        "}\n",
        "\n",
        "def pyg_data_to_mol(data):\n",
        "    mol = Chem.RWMol()\n",
        "\n",
        "    # Add atoms\n",
        "    for x in data.x.squeeze().tolist():  # z contains atomic numbers\n",
        "        atom_num = int(x)\n",
        "        mol.AddAtom(Chem.Atom(atom_labels[x]))\n",
        "\n",
        "    # Add bonds\n",
        "    edge_index = data.edge_index\n",
        "    edge_attr = data.edge_attr  # bond type\n",
        "    num_edges = edge_index.size(1)\n",
        "\n",
        "    for i in range(0, num_edges):  # edges are duplicated in PyG (both directions)\n",
        "        start = edge_index[0, i].item()\n",
        "        end = edge_index[1, i].item()\n",
        "        bond_type_val = int(edge_attr[i].item())\n",
        "\n",
        "        if bond_type_val == 1:\n",
        "            bond_type = Chem.BondType.SINGLE\n",
        "        elif bond_type_val == 2:\n",
        "            bond_type = Chem.BondType.DOUBLE\n",
        "        elif bond_type_val == 3:\n",
        "            bond_type = Chem.BondType.TRIPLE\n",
        "        else:\n",
        "            bond_type = Chem.BondType.SINGLE  # default\n",
        "\n",
        "        try:\n",
        "            mol.AddBond(start, end, bond_type)\n",
        "        except:\n",
        "            pass\n",
        "            # print(f\"Error adding bond between {start} and {end}\")\n",
        "        # mol.AddBond(start, end, bond_type)\n",
        "\n",
        "    return mol.GetMol()\n",
        "\n",
        "def MolTo3DView(mol, size=(300, 300), style=\"stick\", surface=False, opacity=0.5):\n",
        "    \"\"\"Draw molecule in 3D\n",
        "\n",
        "    Args:\n",
        "    ----\n",
        "        mol: rdMol, molecule to show\n",
        "        size: tuple(int, int), canvas size\n",
        "        style: str, type of drawing molecule\n",
        "               style can be 'line', 'stick', 'sphere', 'carton'\n",
        "        surface, bool, display SAS\n",
        "        opacity, float, opacity of surface, range 0.0-1.0\n",
        "    Return:\n",
        "    ----\n",
        "        viewer: py3Dmol.view, a class for constructing embedded 3Dmol.js views in ipython notebooks.\n",
        "    \"\"\"\n",
        "    assert style in ('line', 'stick', 'sphere', 'carton')\n",
        "\n",
        "    mol = Chem.AddHs(mol)\n",
        "    AllChem.EmbedMolecule(mol)\n",
        "    AllChem.MMFFOptimizeMolecule(mol, maxIters=200)\n",
        "    mblock = Chem.MolToMolBlock(mol)\n",
        "    viewer = py3Dmol.view(width=size[0], height=size[1])\n",
        "    viewer.addModel(mblock, 'mol')\n",
        "    viewer.setStyle({style:{}})\n",
        "    if surface:\n",
        "        viewer.addSurface(py3Dmol.SAS, {'opacity': opacity})\n",
        "    viewer.zoomTo()\n",
        "    return viewer\n",
        "\n",
        "####### GRAPH VISUALISATIONS #######\n",
        "\n",
        "class Graph(object):\n",
        "    def __init__(self, edge_index, x, y):\n",
        "        \"\"\" Graph structure\n",
        "            for a mini-batch it will store a big (sparse) graph\n",
        "            representing the entire batch\n",
        "        Args:\n",
        "            x: node features  [num_nodes x num_feats]\n",
        "            y: graph labels   [num_graphs]\n",
        "            edge_index: list of edges [2 x num_edges]\n",
        "        \"\"\"\n",
        "        self.edge_index = edge_index\n",
        "        self.x = x.to(torch.float32)\n",
        "        self.y = y\n",
        "        self.num_nodes = self.x.shape[0]\n",
        "\n",
        "    #ignore this for now, it will be useful for batching\n",
        "    def set_batch(self, batch):\n",
        "        \"\"\" list of ints that maps each node to the graph it belongs to\n",
        "            e.g. for batch = [0,0,0,1,1,1,1]: the first 3 nodes belong to graph_0 while\n",
        "            the last 4 belong to graph_1\n",
        "        \"\"\"\n",
        "        self.batch = batch\n",
        "\n",
        "    # this function return a sparse tensor\n",
        "    def get_adjacency_matrix(self):\n",
        "        \"\"\" from the list of edges create\n",
        "        a num_nodes x num_nodes sparse adjacency matrix\n",
        "        \"\"\"\n",
        "        return torch.sparse.LongTensor(self.edge_index,\n",
        "                              # we work with a binary adj containing 1 if an edge exist\n",
        "                              torch.ones((self.edge_index.shape[1])),\n",
        "                              torch.Size((self.num_nodes, self.num_nodes))\n",
        "                              )\n",
        "\n",
        "def draw_one_graph(ax, edges, label=None, node_emb=None, layout=None, special_color=False):\n",
        "    \"\"\"draw a graph with networkx based on adjacency matrix (edges)\n",
        "    graph labels could be displayed as a title for each graph\n",
        "    node_emb could be displayed in colors\n",
        "    \"\"\"\n",
        "    graph = nx.Graph()\n",
        "    edges = zip(edges[0], edges[1])\n",
        "    graph.add_edges_from(edges)\n",
        "    node_pos = layout(graph)\n",
        "    #add colors according to node embeding\n",
        "    if (node_emb is not None) or special_color:\n",
        "        color_map = []\n",
        "        node_list = [node[0] for node in graph.nodes(data = True)]\n",
        "        for i,node in enumerate(node_list):\n",
        "            #just ignore this branch\n",
        "            if special_color:\n",
        "                if len(node_list) == 3:\n",
        "                    crt_color = (1,0,0)\n",
        "                elif len(node_list) == 5:\n",
        "                    crt_color = (0,1,0)\n",
        "                elif len(node_list) == 4:\n",
        "                    crt_color = (1,1,0)\n",
        "                else:\n",
        "                  special_list = [(1,0,0)] * 3 + [(0,1,0)] * 5 + [(1,1,0)] * 4\n",
        "                  crt_color = special_list[i]\n",
        "            else:\n",
        "                crt_node_emb = node_emb[node]\n",
        "                #map float number (node embeding) to a color\n",
        "                crt_color = cm.gist_rainbow(crt_node_emb, bytes=True)\n",
        "                crt_color = (crt_color[0]/255.0, crt_color[1]/255.0, crt_color[2]/255.0, crt_color[3]/255.0)\n",
        "            color_map.append(crt_color)\n",
        "\n",
        "        nx.draw_networkx_nodes(graph,node_pos, node_color=color_map,\n",
        "                        nodelist = node_list, ax=ax)\n",
        "        nx.draw_networkx_edges(graph, node_pos, ax=ax)\n",
        "        nx.draw_networkx_labels(graph,node_pos, ax=ax)\n",
        "    else:\n",
        "        nx.draw_networkx(graph, node_pos, ax=ax)\n",
        "\n",
        "def gallery(graphs, labels=None, node_emb=None, special_color=False, max_graphs=4, max_fig_size=(40, 10), layout=nx.layout.kamada_kawai_layout):\n",
        "    ''' Draw multiple graphs as a gallery\n",
        "    Args:\n",
        "      graphs: torch_geometrics.dataset object/ List of Graph objects\n",
        "      labels: num_graphs\n",
        "      node_emb: num_graphs* [num_nodes x num_ch]\n",
        "      max_graphs: maximum graphs display\n",
        "    '''\n",
        "    num_graphs = min(len(graphs), max_graphs)\n",
        "    ff, axes = plt.subplots(1, num_graphs,\n",
        "                            figsize=max_fig_size,\n",
        "                            subplot_kw={'xticks': [], 'yticks': []})\n",
        "    if num_graphs == 1:\n",
        "        axes = [axes]\n",
        "    if node_emb is None:\n",
        "        node_emb = num_graphs*[None]\n",
        "    if labels is None:\n",
        "        labels = num_graphs * [\" \"]\n",
        "\n",
        "\n",
        "    for i in range(num_graphs):\n",
        "        draw_one_graph(axes[i], graphs[i].edge_index.numpy(), labels[i], node_emb[i], layout, special_color)\n",
        "        if labels[i] != \" \":\n",
        "            axes[i].set_title(f\"Target: {labels[i]}\", fontsize=28)\n",
        "        axes[i].set_axis_off()\n",
        "    plt.show()\n",
        "\n",
        "def hash_node_embedings(node_emb):\n",
        "  \"\"\" Hash the tensor representing nodes' features\n",
        "  to a number in [0,1] used to represent a color\n",
        "\n",
        "  Args:\n",
        "    node_emb: list of num_graphs arrays, each of dim (num_nodes x num_feats)\n",
        "  Returns:\n",
        "    list of num_graphs arrays in [0,1], each of dim (num_nodes)\n",
        "  \"\"\"\n",
        "  chunk_size_graph = [x.shape[0] for x in node_emb]\n",
        "  start_idx_graph = [0] + list(itertools.accumulate(chunk_size_graph))[:-1]\n",
        "\n",
        "  node_emb_flatten = np.concatenate(node_emb).mean(-1)\n",
        "\n",
        "  min_emb = node_emb_flatten.min()\n",
        "  max_emb = node_emb_flatten.max()\n",
        "  node_emb_flatten = (node_emb_flatten-min_emb)/(max_emb-min_emb)\n",
        "\n",
        "  #split in graphs again according to (start_idx_graph, chunk_size_graph)\n",
        "  node_emb_hashed = [node_emb_flatten[i:i+l] for (i,l) in zip(start_idx_graph, chunk_size_graph)]\n",
        "  return node_emb_hashed\n",
        "\n",
        "####### PLOTS #######\n",
        "\n",
        "def update_stats(training_stats, epoch_stats):\n",
        "    \"\"\" Store metrics along the training\n",
        "    Args:\n",
        "      epoch_stats: dict containg metrics about one epoch\n",
        "      training_stats: dict containing lists of metrics along training\n",
        "    Returns:\n",
        "      updated training_stats\n",
        "    \"\"\"\n",
        "    if training_stats is None:\n",
        "        training_stats = {}\n",
        "        for key in epoch_stats.keys():\n",
        "            training_stats[key] = []\n",
        "    for key,val in epoch_stats.items():\n",
        "        training_stats[key].append(val)\n",
        "    return training_stats\n",
        "\n",
        "def plot_stats(training_stats, figsize=(5, 5), name=\"\"):\n",
        "    \"\"\" Create one plot for each metric stored in training_stats\n",
        "    \"\"\"\n",
        "    stats_names = [key[6:] for key in training_stats.keys() if key.startswith('train_')]\n",
        "    f, ax = plt.subplots(len(stats_names), 1, figsize=figsize)\n",
        "    if len(stats_names)==1:\n",
        "        ax = np.array([ax])\n",
        "    for key, axx in zip(stats_names, ax.reshape(-1,)):\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'train_{key}'],\n",
        "            label=f\"Training {key}\")\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'val_{key}'],\n",
        "            label=f\"Validation {key}\")\n",
        "        axx.set_xlabel(\"Training epoch\")\n",
        "        axx.set_ylabel(key)\n",
        "        axx.legend()\n",
        "    plt.title(name)\n",
        "\n",
        "\n",
        "def get_color_coded_str(i, color):\n",
        "    return \"\\033[3{}m{}\\033[0m\".format(int(color), int(i))\n",
        "\n",
        "def print_color_numpy(map, list_graphs):\n",
        "    \"\"\" print matrix map in color according to list_graphs\n",
        "    \"\"\"\n",
        "    list_blocks = []\n",
        "    for i,graph in enumerate(list_graphs):\n",
        "        block_i = (i+1)*np.ones((graph.num_nodes,graph.num_nodes))\n",
        "        list_blocks += [block_i]\n",
        "    block_color = block_diag(*list_blocks)\n",
        "\n",
        "    map_modified = np.vectorize(get_color_coded_str)(map, block_color)\n",
        "    print(\"\\n\".join([\" \".join([\"{}\"]*map.shape[0])]*map.shape[1]).format(*[x for y in map_modified.tolist() for x in y]))"
      ],
      "metadata": {
        "id": "wXl6eCHN7ruc",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ZINC Dataset"
      ],
      "metadata": {
        "id": "frP6pPcc_gsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[ZINC](https://arxiv.org/abs/1610.02415) is a dataset for graph-regression that contains 12,000 molecular graphs with up to 38 nodes each. Node features denote atom type, edge features denote bond type, and the task is to predict the constrained solubility (a scalar number) for each molecule. Let's load it in from [torch_geometric.dataset](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html#torch_geometric.datasets.ZINC) and see what it contains:"
      ],
      "metadata": {
        "id": "4Xy_W0v72XV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download ZINC dataset from PyG\n",
        "train_zinc_dataset = ZINC(root='', split='train', subset=True)\n",
        "val_zinc_dataset = ZINC(root='', split='val', subset=True)\n",
        "test_zinc_dataset = ZINC(root='', split='test', subset=True)\n",
        "\n",
        "print(f\"\\nTrain examples: {len(train_zinc_dataset)}\")\n",
        "print(f\"Val examples: {len(val_zinc_dataset)}\")\n",
        "print(f\"Test examples: {len(test_zinc_dataset)}\\n\")\n",
        "\n",
        "one_graph = train_zinc_dataset[0]\n",
        "\n",
        "print(f\"First graph contains {one_graph.x.shape[0]} nodes, each characterised by {one_graph.x.shape[1]} features\")\n",
        "print(f\"Graph labels have shape: {one_graph.y.shape}\")"
      ],
      "metadata": {
        "id": "tecyFVuuBf9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each molecular graph is stored as a [torch_geometric.Data](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data) object. The node features `x` denote atom type and have the shape `[num_nodes, 1]`, and the edge features `edge_attr` denote bond type. Note that instead of storing an entire adjacency matrix to describe the graph structure, edges are stored more efficiently in a `edge_index`, which is as a list of edges of shape `[2, num_edges]`. Here, `y` contains the molecule's constrained solubility value, which your GNN try to will predict."
      ],
      "metadata": {
        "id": "FdamnLff2ohX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(one_graph)"
      ],
      "metadata": {
        "id": "S0H8NPJc2n6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's visualize the molecular graph using the `networkx` library."
      ],
      "metadata": {
        "id": "004Aodbl3nPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize molecular graph with networkx function pre-defined above\n",
        "gallery([one_graph], labels=np.array([one_graph.y]), max_fig_size=(8,10))"
      ],
      "metadata": {
        "id": "gtpOvopP1Tzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will use RDKit to get a more representative view of the molecules in this dataset:"
      ],
      "metadata": {
        "id": "EfS8uiK3AYz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Molecular visualization with RDKit, showing the first 5 graphs in the ZINC dataset\n",
        "mols_list = []\n",
        "for i in range(5):\n",
        "  mol = pyg_data_to_mol(train_zinc_dataset[i])\n",
        "  Chem.SanitizeMol(mol)\n",
        "  mols_list.append(mol)\n",
        "\n",
        "img = Draw.MolsToGridImage(\n",
        "    mols_list,\n",
        "    molsPerRow=5,\n",
        "    subImgSize=(250, 250),\n",
        "    legends=[f\"Mol {i+1}\" for i in range(len(mols_list))]\n",
        ")\n",
        "img"
      ],
      "metadata": {
        "id": "yflMTJrs04ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get a more interactive feel for each molecular graph, we can also visualize it in 3D with py3Dmol. Try rotating the molecule around and zooming in and out to get a better sense of its geometry:"
      ],
      "metadata": {
        "id": "F670S2hGA2Ua"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3D molecular visualization\n",
        "mol = pyg_data_to_mol(train_zinc_dataset[0])\n",
        "Chem.SanitizeMol(mol)\n",
        "viewer = MolTo3DView(mol)\n",
        "viewer.show()"
      ],
      "metadata": {
        "id": "X6qmlvyQ1WcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üëØ Section 4: Mini-batching for graph data\n",
        "\n",
        "Since we are now dealing with multiple graphs, we need to figure out how to store them in mini-batches to be able to make the computation as efficient as possible. For some types of data, stacking samples in mini-batches is a trivial task. For example, images of $32\\times32$ pixels are easy to batch because they have the same dimension (obtaining a tensor of dimension $batch\\_{size}\\times32\\times32$). On the other hand, graphs come in different sizes with adjacency matrices of different shapes:"
      ],
      "metadata": {
        "id": "9fdiDkK5W8fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'First graph : {train_zinc_dataset[0].x.shape} with adjacency {(train_zinc_dataset[0].num_nodes, train_zinc_dataset[0].num_nodes)}')\n",
        "print(f'Second graph: {train_zinc_dataset[1].x.shape} with adjacency {(train_zinc_dataset[1].num_nodes, train_zinc_dataset[1].num_nodes)}')\n",
        "print(f'Third graph : {train_zinc_dataset[2].x.shape} with adjacency {(train_zinc_dataset[2].num_nodes, train_zinc_dataset[2].num_nodes)}')"
      ],
      "metadata": {
        "id": "6jSbebDEW_tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One solution for this is to create a single *sparse* graph as the union of all the graphs in the mini-batch as follow:\n",
        "\n",
        "1. stack the features $x$ for all the nodes in all the graphs\n",
        "2. stack the labels $y$ for all the nodes in all the graphs\n",
        "3. stack all the adjacency matrices $A_i$ as diagonal blocks in the new adjacency matrix\n",
        "\n",
        "This way, we will obtain a new graph containing $\\sum_{i=1}^{B}|V_i|$ nodes, where $B$ is the batch_size and by $|V_i|$ we denote the number of nodes in graph $i$. Note that since **no** edges connect nodes from different graphs,  the  information propagation will not be affected by the way we store it.  \n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1RwI0CYA57S0OgLxgHgV6PBFNG9tnGvGR\" width=\"500\">\n",
        "</center>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1Ux65wTJLXCfJ4TI4Up4mCHkaSja8NgrJ\" width=\"500\">\n",
        "</center>\n",
        "\n",
        "As you can see, the resulting matrix contains many zeros (sparse), thus our choice of storing the adjacency matrix as a sparse tensor can indeed bring us efficiency.\n",
        "\n",
        "Until now, we have a way to store the graphs in a mini-batch such that they could be efficiently processed.\n",
        "\n",
        "However, we need to also be able to extract information from this structure, to recover the graphs that it contains. For this, we need to remember what initial graph each node belongs to.\n",
        "\n",
        "We will do this by storing a list of indices `(self.batch)`, which map each node in the batch-graph to the initial graph it belong to. For example `batch=[0,0,0,1,1,2,2,2]` indicates that first 3 nodes belong to $G_0$, the next 2 nodes belong to $G_1$ and the last 3 nodes belong to $G_2$.\n",
        "\n"
      ],
      "metadata": {
        "id": "zpJelcUDXGoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mini_batch(graph_list: List[Graph]) -> Graph:\n",
        "    \"\"\" Built a sparse graph from a batch of graphs\n",
        "    Args:\n",
        "        graph_list: list of Graph objects in a batch\n",
        "    Returns:\n",
        "        a big (sparse) Graph representing the entire batch\n",
        "    \"\"\"\n",
        "    #insert first graph into the structure\n",
        "    batch_edge_index = graph_list[0].edge_index\n",
        "    batch_x = graph_list[0].x\n",
        "    batch_y = graph_list[0].y\n",
        "    batch_batch = torch.zeros((graph_list[0].num_nodes), dtype=torch.int64)\n",
        "\n",
        "    nodes_count = graph_list[0].num_nodes\n",
        "\n",
        "    #append the rest of the graphs to the structure\n",
        "    for idx, graph in enumerate(graph_list[1:]):\n",
        "        # concat the features\n",
        "        batch_x = torch.cat((batch_x, graph.x))\n",
        "        # concat the labels\n",
        "        batch_y = torch.cat((batch_y, graph.y))\n",
        "\n",
        "        # concat the adjacency matrix as a block diagonal matrix\n",
        "\n",
        "        # here we have to modify the current graph edge index by adding\n",
        "        # to the row and column the number of nodes we have already\n",
        "        # added to the batch, this way when computing the sparse block matrix,\n",
        "        # we position the nodes correctly\n",
        "        batch_edge_index = torch.cat((\n",
        "            batch_edge_index,\n",
        "            torch.add(graph.edge_index, nodes_count))\n",
        "        , dim=1)\n",
        "        nodes_count += graph.num_nodes\n",
        "\n",
        "        # create the array of indexes mapping nodes in the batch-graph\n",
        "        # to the graph they belong to\n",
        "        # specify the mapping between the new nodes and the graph they belong to (idx+1)\n",
        "\n",
        "        # here we append a vector of [idx+1, idx+1,...] which has dimension graph.num_nodes\n",
        "        # to our existing batch_batch vector to keep track of the nodes\n",
        "        batch_batch = torch.cat((\n",
        "            batch_batch,\n",
        "            torch.full((graph.num_nodes,), idx + 1)\n",
        "        ))\n",
        "\n",
        "    #create the big sparse graph\n",
        "    batch_graph = Graph(batch_edge_index, batch_x, batch_y)\n",
        "    #attach the index array to the Graph structure\n",
        "    batch_graph.set_batch(batch_batch)\n",
        "    return batch_graph"
      ],
      "metadata": {
        "id": "zEL_s1tDXBmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [Run me] Visualize the mini-batching for a small list of batch_size=3 graphs\n",
        "\n",
        "# 3 random custom-designed graphs for visualisations\n",
        "graph1 = Graph(x=torch.rand((3,32)),\n",
        "               y=torch.rand((1)),\n",
        "               edge_index=torch.tensor([[0,0,0,1,1,1,2,2,2],[0,1,2,0,1,2,0,1,2]]))\n",
        "graph2 = Graph(x=torch.rand((5,32)),\n",
        "               y=torch.rand((1)),\n",
        "               edge_index=torch.tensor([[0,0,0,0,0,1,1,1,2,1,2,3,4], [0,1,2,3,4,2,3,4,4,0,0,0,0]]))\n",
        "graph3 = Graph(x=torch.rand((4,32)),\n",
        "               y=torch.rand((1)),\n",
        "              edge_index=torch.tensor([[0,1,2,3],[1,2,3,0]]))\n",
        "list_graphs = [graph1, graph2, graph3]\n",
        "\n",
        "# create a mini-batch from these 3 graphs\n",
        "batch_sample = create_mini_batch(list_graphs)\n",
        "\n",
        "# show statistics about the new graph built from this batch of graphs\n",
        "print(f\"Batch number_of_nodes: {batch_sample.num_nodes}\")\n",
        "print(f\"Batch features shape: {batch_sample.x.shape}\")\n",
        "print(f\"Batch labels shape: {batch_sample.y.shape}\")\n",
        "\n",
        "print(f\"Batch adjacency: \")\n",
        "print_color_numpy(batch_sample.get_adjacency_matrix().to_dense().numpy(), list_graphs)\n",
        "\n",
        "gallery([graph1, graph2, graph3, batch_sample], max_fig_size=(20,6), special_color=True)\n",
        "print(f\"Also, we have access to which graph each node belongs to: {batch_sample.batch}\\n\")\n"
      ],
      "metadata": {
        "id": "_ovaA_jcXgMT",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the adjacency matrix above is in a *block diagonal* structure. With this structure, effectively each graph is independent from the other - exactly what we want for batching! We would not want the representations of a graph to affect the representation of a different graph.\n",
        "\n",
        "When training our model, manually implementing this batching process can get quite arduous. Fortunately, we can rely on the `DataLoader` [module](https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html) from PyTorch to handle the batching for us!"
      ],
      "metadata": {
        "id": "DEKYRjEPXz5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloaders with batch size = 128\n",
        "train_loader = DataLoader(train_zinc_dataset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_zinc_dataset, batch_size=128, shuffle=False)\n",
        "test_loader = DataLoader(test_zinc_dataset, batch_size=128, shuffle=False)"
      ],
      "metadata": {
        "id": "3lxG8TLlVMld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üï∏Ô∏è Section 5: Graph Regression with GIN"
      ],
      "metadata": {
        "id": "VzZFotLNX5Kf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we will design a  Graph Neural Network model, similar to the one used on Cora, with the following modifications:\n",
        "* graph-level prediction instead of node-level prediction\n",
        "* regression instead of classification\n",
        "* to obtain a *provablly more powerful architecture*, we will go beyond a GCN Layer and implement a [Graph Isomorphism Network (**GIN**)](https://arxiv.org/abs/1810.00826)\n",
        "\n",
        "One simple instantiation of GIN Layer processes the graph according to the following message passing equation, where $\\epsilon_k$ is a learnable scalar\n",
        "\n",
        "\\begin{equation}\n",
        "X^{k+1}= \\text{MLP}_k\\big(AX^k + (1+\\epsilon_k)X^k\\big)\n",
        "\\end{equation}\n"
      ],
      "metadata": {
        "id": "koJH5ms340JA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üíª **Task 6:** Implement GIN using PyTorch Geometric\n",
        "\n",
        "Since you've already implemented message passing the hard way in the section above, you will build your model using PyTorch Geometric modules this time. Some functions that may come in handy include:\n",
        "- `torch.nn.Embedding` ([documentation](https://docs.pytorch.org/docs/stable/generated/torch.nn.Embedding.html)) to embed the inital atom input features\n",
        "- `torch_geometric.nn.GINConv` ([documentation](https://pytorch-geometric.readthedocs.io/en/2.5.1/generated/torch_geometric.nn.conv.GINConv.html))\n",
        "- `torch_geometric.nn.models.MLP` ([documentation](https://pytorch-geometric.readthedocs.io/en/stable/generated/torch_geometric.nn.models.MLP.html))\n",
        "- `squeeze()` ([documentation](https://docs.pytorch.org/docs/stable/generated/torch.squeeze.html)) to adjust the dimensions of your features\n",
        "\n",
        "Also, remember that you are performing a graph-level regression task this time! To obtain a graph-level representation, you will need to pool the individual node representations together at the end with the torch `scatter` [function](https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html). For now, you can ignore the `residual` parameter; this will come into play later on. And again, don't forget your activation functions!"
      ],
      "metadata": {
        "id": "i83vat1VD1dR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GINRegression(nn.Module):\n",
        "    def __init__(self, num_layers, input_dim, emb_dim, residual):\n",
        "        super().__init__()\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "    def forward(self, data):\n",
        "        # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "HDjIW7tFXo4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíª Task 7: Train your GNN on graph regression"
      ],
      "metadata": {
        "id": "OPe5eKl1Z4ZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we define training and evaluation functions. We will track L1 loss, which\n",
        "# corresponds to mean absolute error (MAE) for regression\n",
        "def train(model, loader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(data)\n",
        "\n",
        "        loss = F.l1_loss(pred, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return (total_loss / len(loader))\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        pred = model(data)\n",
        "        loss = F.l1_loss(pred, data.y)\n",
        "        total_loss += loss.item()\n",
        "    return (total_loss / len(loader))\n",
        "\n",
        "def run_experiment(model):\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    epochs = 20\n",
        "    for epoch in range(1, epochs + 1):\n",
        "      train_mae = train(model, train_loader, optimizer, device)\n",
        "      val_mae = evaluate(model, val_loader, device)\n",
        "      print(f\"[Epoch {epoch}] | Train MAE: {train_mae:.4f} | Val MAE: {val_mae:.4f}\")\n",
        "\n",
        "    test_mae = evaluate(model, test_loader, device)\n",
        "    print(\"Final test MAE: {:.4f}\".format(test_mae))"
      ],
      "metadata": {
        "id": "Bwyj0buqVSbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run GINRegression on graph regression task\n",
        "model = GINRegression(\n",
        "    num_layers=4,\n",
        "    input_dim=28,\n",
        "    emb_dim=64,\n",
        "    residual=False\n",
        ").to(device)\n",
        "run_experiment(model)"
      ],
      "metadata": {
        "id": "OrP-oU-FWbDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now try runinng your model with more layers. How does the performance change?"
      ],
      "metadata": {
        "id": "OUucW0D9WuSb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deep_model = GINRegression(\n",
        "    num_layers=16,\n",
        "    input_dim=28,\n",
        "    emb_dim=64,\n",
        "    residual=False\n",
        ").to(device)\n",
        "run_experiment(deep_model)"
      ],
      "metadata": {
        "id": "6I9k0N1TWt2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíª Task 8: Adding residual connections\n",
        "\n",
        "The phenomenon you witnessed above is called *over-smoothing*, which is when node-representations become indistinguishable from each other as the number of network layers increases.\n",
        "\n",
        "The full GIN architecture as introduced in the original [paper](https://arxiv.org/pdf/1810.00826.pdf), does not use only the final output for predictions. Instead, it creates a graph representation from the representation of all the intermediate layers:\n",
        "\n",
        "\\begin{equation}\n",
        "h_G = CONCAT\\big(\\oplus_{v \\in G}\\{h_v^{(k)}\\}| k=0,1..(K-1) \\big)\n",
        "\\end{equation}\n",
        "\n",
        "where $\\oplus_{v \\in G}\\{h_v^{(k)}\\}$ represents the graph-level representations at layer $k$, obtained by summing the representations from all the nodes $v \\in G$. These are also referred to as *residual connections*, and have been shown to help combat the effects of over-smoothing.\n",
        "\n",
        "Adjust your `GINRegression` model to incorporate residual connections, and re-run training and evaluation."
      ],
      "metadata": {
        "id": "KcW307FO5TZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deep_residual_model = GINRegression(\n",
        "    num_layers=16,\n",
        "    input_dim=28,\n",
        "    emb_dim=64,\n",
        "    residual=True\n",
        ").to(device)\n",
        "run_experiment(deep_residual_model)"
      ],
      "metadata": {
        "id": "vSZbmmBtYZZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíª Task 9 [optional]: Adding edge features\n",
        "\n",
        "Notice that we did not use edge features (i.e. bond information) when computing the graph-level representations, which may help improve our molecular embeddings. Modify your `GINRegression` model to incorporate this edge information, and see how the performance changes. You may find the `torch_geometric.nn.conv.GINEConv` ([documentation](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.nn.conv.GINEConv.html)) function helpful."
      ],
      "metadata": {
        "id": "9lRH2gj-unW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "mVv3Vz-KAT18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéâ   Kraj\n",
        "\n",
        "That's all for today! We hope now you've learned to love graphs as much as we do ‚ù§Ô∏è\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1A-a1YWc6c8ZWFV_4gblsnVi85S8sBRuv\" width=\"500\">\n",
        "</center>"
      ],
      "metadata": {
        "id": "LasBXNBPLzxM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vvEtWvWoKUSK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
